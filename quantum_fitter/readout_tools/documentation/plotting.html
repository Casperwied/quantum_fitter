<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>quantum_fitter.readout_tools.plotting API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:#555;padding-bottom:.5em;border-bottom:1px solid silver}.homelink:hover{color:inherit}.homelink img{max-width:20%;max-height:5em;margin:auto;margin-bottom:.3em}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>readout_tools.plotting</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import numpy as np
import pandas as pd
from quantum_fitter.readout_tools import *

class Plotting(Fitting):
    &#34;&#34;&#34;This class contains all plotting functions.
    &#34;&#34;&#34;
    def __init__(self, filePath=None, channelName=None, entries=None, state_entries=None, labels=None, 
                 size=None, scalar=True, pca=True, cv_params=None, verbose=1, kfolds=10, figsize=(10, 6),
                 alpha=0.70):
        &#34;&#34;&#34;Initializes the class and sits figure size an alpha val.

        Args:
            filePath (string, optional): File path for the Labber (h5file) file containing the IQ data. Defaults to None.
            channelName (string, optional): Channel name contained IQ data. If None the first trace in the file is used. Defaults to None.
            state_entries (list, optional): A list containing the wanted entries for classification. If None the two entries with the largest and smallest mean are used. Defaults to None.
            labels (list, optional): A list containing the labels for the states. Labels can be integers or a strings. If None numbers from 0 to len(number of states) is used. Defaults to None.
            size (int, optional): The size of the data set used. Must be integer. Defaults to None.
            scalar (bool, optional): If True the data is standardized in the pipeline. This ensures the optimal conditions for the machine learning. Defaults to True.
            pca (bool, optional): If True the data is transformed by PCA in the pipeline. This ensures the optimal conditions for the machine learning. Defaults to True.
            cv_params (_type_, optional): If None the standard parameters are used. These can be changed afterwards. Defaults to None.
            verbose (int, optional): If 0 only the result is returned. Defaults to 1.
            kfolds (int, optional): Number of splits in the dataset. Used for crossvalidation. Defaults to 10.
            figsize (tuple, optional): The size of the figure. Defaults to (10, 6).
            alpha (float, optional): Transparency value of beta points. Float between [0,1]. Defaults to 0.70.
        &#34;&#34;&#34;
        super().__init__(filePath, channelName, entries, state_entries, labels, size, scalar, pca, cv_params, verbose, kfolds)

        self.figsize = figsize
        self.alpha = alpha
    
    def plot_classifier_decision_function(self, resolution=350, ax=None, plot_support=True):
        &#34;&#34;&#34;Plots the decision function for a 2D decision function

        Args:
            resolution (int, optional): Resolution of the plotted decision function. Defaults to 350.
            ax (string, optional): The plot ax to use, if ax=None then new ax is generated. Defaults to None.
            plot_support (bool, optional): Plots exstra data, just nicense. Defaults to True.
        &#34;&#34;&#34;
        if ax is None:
            ax = plt.gca()
        xlim = ax.get_xlim()
        ylim = ax.get_ylim()

        # create grid to evaluate classifiermodel
        x = np.linspace(xlim[0], xlim[1], resolution)
        y = np.linspace(ylim[0], ylim[1], resolution)
        Y, X = np.meshgrid(y, x)
        xy = np.c_[X.ravel(), Y.ravel()]    #xy = np.array([X.ravel(), Y.ravel()]).T

        self._try_fit()
        
        if ((hasattr(self.cv_search, &#39;decision_function&#39;)) and (len(self._states_labels) &lt; 3)):
            P = self.cv_search.decision_function(xy)
        else:
            P = self.cv_search.predict(xy)

        self.decision_function = P.reshape(X.shape)

        if ((hasattr(self.cv_search, &#39;decision_function&#39;)) and (len(self._states_labels) &lt; 3)):
            levels = [-1, 0, 1]
            linestyles = [&#39;--&#39;, &#39;-&#39;, &#39;--&#39;]
        else:
            list, j = [], 0
            for i in range(len(self.state_entries)):
                num = i-j
                if (i % 2) == 0:
                    list.append(0.5 + num*0.5)
                else:
                    j += 1
                    list.append(0.5 - num*0.5)
               
            levels = list.sort()
            linestyles = [&#39;-&#39;] * len(self.state_entries)

        ax.contour(X, Y, self.decision_function, colors=&#39;k&#39;,
                   alpha=0.5, levels=levels,
                   linestyles=linestyles)

        # plot support vectors
        if hasattr(self.cv_search, &#39;support_vectors_&#39;):
            if plot_support:
                ax.scatter(self.cv_search.support_vectors_[:, 0],
                           self.cv_search.support_vectors_[:, 1],
                           s=300,
                           alpha=0.7, linewidth=1,
                           facecolors=&#39;None&#39;, edgecolors=&#34;k&#34;)

        ax.set_xlim(xlim)
        ax.set_ylim(ylim)
    
    def plot_classifier(self, X=None, y=None, sample_weight=None, class_plot=True, save_fig=False, title=None):
        &#34;&#34;&#34;Plotting fuction for SVM fits

        Args:
            X (list, optional): The X-data to use. If None the Initial states are used: self.X_train. Defaults to None.
            y (list, optional): The y-data to use. If None the Initial states are used: self.y_train. Defaults to None.
            sample_weight (list, optional): The calculated weights. Defaults to None.
            class_plot (bool, optional): If True the classifiers plotted. Defaults to True.
            save_fig (bool, optional): If True the figure is saved. Defaults to False.
            title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

        Returns:
            ax (object): The figure object
        &#34;&#34;&#34;
        fig, ax = plt.subplots(figsize=self.figsize)

        if X is None:
            X = np.array(self.X_train)
            
        if y is None:
            y = np.array(self.y_train)
        
        if isinstance(sample_weight, int) == False:
            sample_weight = self.weights
        
        for i in np.unique(y):   
            plt.scatter(X[:, 0][y==i], X[:, 1][y==i], s=50 * sample_weight[y==i], alpha=self.alpha, cmap=&#39;Spectral&#39;, label=f&#39;State {int(i)}&#39;)
        
        if class_plot == True:
            self.plot_classifier_decision_function()

        ax.set_xlabel(&#34;I (V)&#34;), ax.set_ylabel(&#34;Q (V)&#34;)
        
        if title == None:
            kernel = self.cv_search.best_estimator_[-1].kernel
            title = self._get_file_name_from_path(self._filePath)
        
        ax.set_title(f&#39;Classifiter training plot, kernel: {kernel}\n&#39; + title)
        
        plt.legend()
        plt.tight_layout()
        
        if save_fig == True:
            self.save_fig(self.cv_search, name=&#39;classifier_plot&#39;,  format=&#39;.svg&#39;, dpi=600)
        plt.show()
        
        return ax
 
    def plot_testing(self, X=None, save_fig=False, title=None):
        &#34;&#34;&#34;A function for plotting the testing of a dataset.

        Args:
            X (list, optional): The X-data to use. If None the Initial states are used: self.X_test. Defaults to None.
            save_fig (bool, optional): If True the figure is saved. Defaults to False.
            title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

        Returns:
            ax (object): The figure object
        &#34;&#34;&#34;
    
        if X is None:
            X = self.X_test
        
        predcition = np.array(self.cv_search.predict(X))
        unique, counts = np.unique(predcition, return_counts=True)

        fig, ax = plt.subplots(figsize=(10, 6))

        for i in np.unique(predcition):   
            plt.scatter(X[:, 0][predcition==i], X[:, 1][predcition==i], s=25, alpha=self.alpha, cmap=&#39;Spectral&#39;, label=f&#39;State {int(i)}, {counts/len(predcition):.3}:.%&#39;)
        
        
        self.plot_classifier_decision_function(plot_support=False)

        ax.set_xlabel(&#34;I&#34;), ax.set_ylabel(&#34;Q&#34;)
        
        if title == None:
            kernel = self.cv_search.best_estimator_[-1].kernel
            title = self._get_file_name_from_path(self._filePath)
        
        ax.set_title(f&#39;Classifiter testing plot, kernel: {kernel}\n&#39; + title )
        
        plt.legend()
        plt.tight_layout()

        if save_fig == True:
            self.save_fig(self.cv_search, name=&#39;testing_plot&#39;,  format=&#39;.svg&#39;, dpi=600)

        return ax
    
    def plot_ROC(self, X=None, y=None, save_fig=False, title=None):
        &#34;&#34;&#34;Make ROC plots of FPR / TP.

        Args:
            X (list, optional): The X-data to use. If None the Initial states are used: self.X_test. Defaults to None.
            y (list, optional): The y-data to use. If None the Initial states are used: self.y_test. Defaults to None.
            save_fig (bool, optional): If True the figure is saved. Defaults to False.
            title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

        Returns:
            ax (object): The figure object
        &#34;&#34;&#34;
        from sklearn.metrics import roc_curve, auc
        
        fig, ax = plt.subplots(figsize=self.figsize)
        
        if X is None:
            X = self.X_test
            
        if y is None:
            y = self.y_test
        
        # compute y prediction probabilities:
        y_predicted_proba = self.cv_search.predict_proba(X)
        
        n_classes = y_predicted_proba.shape[1]
        
        FPR_list, TPR_list, y_list, y_predicted_proba_list = [], [], [], []
        for i in range(n_classes):
            y_i = np.where((y == i), 1, 0)
            
            # Compute ROC curve and ROC area
            FPR, TPR, _ = roc_curve(y_i, y_predicted_proba[:, i])
            roc_auc = auc(FPR, TPR)

            FPR_list.append(FPR), TPR_list.append(TPR)
            y_list.append(y_i), y_predicted_proba_list.append(y_predicted_proba[:, i])
            
            # plot the ROC curve
            ax.plot(FPR, TPR, label=f&#39;ROC curve state {i} (area = %0.3f)&#39; % roc_auc)
            
            
            
        # First aggregate all false positive rates
        all_fpr = np.unique(np.concatenate(FPR_list))

        # Then interpolate all ROC curves at this points
        mean_tpr = np.zeros_like(all_fpr)
        for i in range(n_classes):
            mean_tpr += np.interp(all_fpr, FPR_list[i], TPR_list[i])

        # Finally average it and compute AUC
        mean_tpr /= n_classes

        FPR_macro = all_fpr
        TPR_macro = mean_tpr
        roc_auc_macro = auc(FPR_macro, TPR_macro)   
                    
        # plot the macro ROC curve
        ax.plot(FPR_macro, TPR_macro, label=f&#39;macro-average ROC curve (area = %0.3f)&#39; % roc_auc_macro, linestyle=&#34;--&#34;)
             
        # plot the micro ROC curve
        FPR_micro, TPR_micro, _ = roc_curve(np.array(y_list).flatten(), np.array(y_predicted_proba_list).flatten())
        #FPR_micro, TPR_micro = np.array(FPR_list).flatten(), np.array(TPR_list).flatten()
        roc_auc_micro = auc(FPR_micro, TPR_micro)  
        
        ax.plot(FPR_micro, TPR_micro, label=f&#39;micro-average ROC curve (area = %0.3f)&#39; % roc_auc_micro, linestyle=&#34;--&#34;)
          
            
            
        ax.plot([0, 1], [0, 1], linestyle=&#39;--&#39;)
        ax.set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05], xlabel=&#39;False Positive Rate&#39;, ylabel=&#39;True Positive Rate&#39;)
        ax.legend(loc=&#34;lower right&#34;)
        
        if title == None:
            kernel = self.cv_search.best_estimator_[-1].kernel
            title = self._get_file_name_from_path(self._filePath)
        
        ax.set_title(f&#39;ROC plot, kernel: {kernel}\n&#39; + title )
        
        
        plt.tight_layout()
        
        if save_fig == True:
            self.save_fig(self.cv_search, name=&#39;roc_plot&#39;,  format=&#39;.svg&#39;, dpi=600)

        return ax
    
    def plot_cv_iterations(self, score_value=&#34;mean_test_score&#34;, save_fig=False, title=None):
        &#34;&#34;&#34;The function the plots the performance of each iteration of cross validation.

        Args:
            score_value (list, optional): The score value to plot on the y axis. If None &#34;mean_test_score&#34; is used. Defaults to None.
            save_fig (bool, optional): If True the figure is saved. Defaults to False.
            title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

        Returns:
            ax (object): The figure object
        &#34;&#34;&#34;
        results = pd.DataFrame(self.cv_search.cv_results_)
        results[&#34;params_str&#34;] = results.params.apply(str)
        results.drop_duplicates(subset=(&#34;params_str&#34;, &#34;iter&#34;), inplace=True)
        
        mean_scores = results.pivot(index=&#34;iter&#34;, columns=&#34;params_str&#34;, values=score_value)
        ax = mean_scores.plot(legend=False, alpha=0.6, figsize=(10, 6))

        labels = [
            f&#34;iter={i}\nn_samples={self.cv_search.n_resources_[i]}\nn_candidates={self.cv_search.n_candidates_[i]}&#34;
            for i in range(self.cv_search.n_iterations_)
        ]

        ax.set_xticks(range(self.cv_search.n_iterations_))
        ax.set_xticklabels(labels, rotation=45, multialignment=&#34;left&#34;)
        ax.set_title(&#34;Scores of candidates over iterations&#34;)
        
        if title == None:
            kernel = self.cv_search.best_estimator_[-1].kernel
            title = self._get_file_name_from_path(self._filePath)
        
        ax.set_title(f&#39;Scores of candidates over iterations, kernel: {kernel} \n&#39; + title)
        
        ax.set_ylabel(score_value.replace(&#34;_&#34;,&#34; &#34;))
        ax.set_xlabel(&#34;iterations&#34;)
        plt.tight_layout()
        
        if save_fig == True:
            self.save_fig(self.cv_search, name=&#39;cv_iterations&#39;,  format=&#39;.svg&#39;, dpi=600)
        
        return ax
    
    def plot_oscillation(self, x=None, y=None, X=None, size=None, mode=&#39;probability&#39;, title=None, state=1):
        &#34;&#34;&#34;Function for oscillation plot. For more information to see example &#34;quick_run&#34;.

        Args:
            x (_type_, optional): If None: self.probability_values or self.expectation_values. Defaults to None.
            y (_type_, optional): If None: self.h5data_log[&#39;axis&#39;]. Defaults to None.
            X (list, optional): The X-data to use. If None the Initial states are used: self.X_test. Defaults to None.
            size (int, optional): The size of the data set used. Must be integer. Defaults to None.
            mode (str, optional): Can be [&#39;probability&#39;,&#39;expectation&#39;]. Defaults to &#39;probability&#39;.
            title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.
            state (int, optional): The state to be calculated. Defaults to 1.

        Returns:
            ax (object): The figure object
        &#34;&#34;&#34;
        if title == None:
            title = self._get_file_name_from_path(self._filePath)
            
        if size == None:
            size = self._int_states.shape[1]

        if hasattr(self, &#39;_osc_state&#39;) == False:
            self._osc_state = None
        
        if hasattr(self, &#39;expectation_values&#39;) == False or size != self.size or self._osc_state != state:
            self.cal_expectation_values(X, size, state=state)

        self._osc_state = state
       
        fig, ax = plt.subplots(figsize=self.figsize)

        if y is None:
            if mode == &#39;expectation&#39;:
                y = self.expectation_values
                ax.set_ylabel(&#39;Expetaction Value&#39;)
                
            if mode == &#39;probability&#39;:
                y = self.probability_values
                if self._osc_state == &#39;all&#39;:
                    ax.set_ylabel(f&#39;Probability&#39;)
                else:
                    ax.set_ylabel(f&#39;Probability of state {int(self._osc_state)}&#39;)
        
        for i, key in enumerate(y.keys()): 
            if x is None:
                x = self.h5data_log[&#39;axis&#39;]
            
            if mode == &#39;probability&#39; and self._osc_state == &#39;all&#39;:
                y = np.array(self.probability_values[key])
                for j in range(y.shape[1]):
                    self.do_fit_oscillation(x=x, y=y[:,j], label=key + f&#39;, state {j}&#39;, ax=ax, color=list(mcolors.TABLEAU_COLORS.values())[j])
            else:
                self.do_fit_oscillation(x=x, y=y[key], label=key, ax=ax, color=list(mcolors.TABLEAU_COLORS.values())[i])
        
        ax.set_xlabel(self.h5data_log[&#39;name&#39;])
        ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
        
        fit_type = r&#39;$A \times sin(\omega x + \varphi) + c$&#39;
        ax.set_title(title + &#39;\n Fit type: &#39; + fit_type)
        
        plt.tight_layout()
        
        return ax
     
    def plot_param_effect(self, plot_dir=None, title=None):
        &#34;&#34;&#34;A function for plotting the effects on a score of a parameter.

        Args:
            plot_dir (dir, optional): A dir containing the score and parameter values. If None self._plot_dir is used Defaults to None.
            title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

        Returns:
            ax (object): The figure object
        &#34;&#34;&#34;
        if plot_dir == None:
            try:
                plot_dir = self._plot_dir
            except:
                print(&#39;self._plot_dir is not defined. Define using self.set_plot_dir()&#39;)
        
        try:
            std = plot_dir[&#39;score_std&#39;]
        except:
            std = None
        
        fig, ax = plt.subplots(figsize=self.figsize)
        
        ax.errorbar(plot_dir[&#39;param_value&#39;], plot_dir[&#39;score_value&#39;], yerr=std)
      
    
        if title == None:
            title = self._get_file_name_from_path(self._filePath)
        
        ax.set_title(f&#39;Scores of candidates over parameter\n&#39; + title)
        
        ax.set_ylabel(plot_dir[&#39;score_name&#39;].replace(&#34;_&#34;,&#34; &#34;))
        ax.set_xlabel(plot_dir[&#39;param_name&#39;].replace(&#34;_&#34;,&#34; &#34;))
        plt.tight_layout()
        
        return ax
        </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="quantum_fitter.readout_tools.plotting.Plotting"><code class="flex name class">
<span>class <span class="ident">Plotting</span></span>
<span>(</span><span>filePath=None, channelName=None, entries=None, state_entries=None, labels=None, size=None, scalar=True, pca=True, cv_params=None, verbose=1, kfolds=10, figsize=(10, 6), alpha=0.7)</span>
</code></dt>
<dd>
<div class="desc"><p>This class contains all plotting functions.</p>
<p>Initializes the class and sits figure size an alpha val.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filePath</code></strong> :&ensp;<code>string</code>, optional</dt>
<dd>File path for the Labber (h5file) file containing the IQ data. Defaults to None.</dd>
<dt><strong><code>channelName</code></strong> :&ensp;<code>string</code>, optional</dt>
<dd>Channel name contained IQ data. If None the first trace in the file is used. Defaults to None.</dd>
<dt><strong><code>state_entries</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>A list containing the wanted entries for classification. If None the two entries with the largest and smallest mean are used. Defaults to None.</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>A list containing the labels for the states. Labels can be integers or a strings. If None numbers from 0 to len(number of states) is used. Defaults to None.</dd>
<dt><strong><code>size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The size of the data set used. Must be integer. Defaults to None.</dd>
<dt><strong><code>scalar</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True the data is standardized in the pipeline. This ensures the optimal conditions for the machine learning. Defaults to True.</dd>
<dt><strong><code>pca</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True the data is transformed by PCA in the pipeline. This ensures the optimal conditions for the machine learning. Defaults to True.</dd>
<dt><strong><code>cv_params</code></strong> :&ensp;<code>_type_</code>, optional</dt>
<dd>If None the standard parameters are used. These can be changed afterwards. Defaults to None.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>If 0 only the result is returned. Defaults to 1.</dd>
<dt><strong><code>kfolds</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of splits in the dataset. Used for crossvalidation. Defaults to 10.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>The size of the figure. Defaults to (10, 6).</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Transparency value of beta points. Float between [0,1]. Defaults to 0.70.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Plotting(Fitting):
    &#34;&#34;&#34;This class contains all plotting functions.
    &#34;&#34;&#34;
    def __init__(self, filePath=None, channelName=None, entries=None, state_entries=None, labels=None, 
                 size=None, scalar=True, pca=True, cv_params=None, verbose=1, kfolds=10, figsize=(10, 6),
                 alpha=0.70):
        &#34;&#34;&#34;Initializes the class and sits figure size an alpha val.

        Args:
            filePath (string, optional): File path for the Labber (h5file) file containing the IQ data. Defaults to None.
            channelName (string, optional): Channel name contained IQ data. If None the first trace in the file is used. Defaults to None.
            state_entries (list, optional): A list containing the wanted entries for classification. If None the two entries with the largest and smallest mean are used. Defaults to None.
            labels (list, optional): A list containing the labels for the states. Labels can be integers or a strings. If None numbers from 0 to len(number of states) is used. Defaults to None.
            size (int, optional): The size of the data set used. Must be integer. Defaults to None.
            scalar (bool, optional): If True the data is standardized in the pipeline. This ensures the optimal conditions for the machine learning. Defaults to True.
            pca (bool, optional): If True the data is transformed by PCA in the pipeline. This ensures the optimal conditions for the machine learning. Defaults to True.
            cv_params (_type_, optional): If None the standard parameters are used. These can be changed afterwards. Defaults to None.
            verbose (int, optional): If 0 only the result is returned. Defaults to 1.
            kfolds (int, optional): Number of splits in the dataset. Used for crossvalidation. Defaults to 10.
            figsize (tuple, optional): The size of the figure. Defaults to (10, 6).
            alpha (float, optional): Transparency value of beta points. Float between [0,1]. Defaults to 0.70.
        &#34;&#34;&#34;
        super().__init__(filePath, channelName, entries, state_entries, labels, size, scalar, pca, cv_params, verbose, kfolds)

        self.figsize = figsize
        self.alpha = alpha
    
    def plot_classifier_decision_function(self, resolution=350, ax=None, plot_support=True):
        &#34;&#34;&#34;Plots the decision function for a 2D decision function

        Args:
            resolution (int, optional): Resolution of the plotted decision function. Defaults to 350.
            ax (string, optional): The plot ax to use, if ax=None then new ax is generated. Defaults to None.
            plot_support (bool, optional): Plots exstra data, just nicense. Defaults to True.
        &#34;&#34;&#34;
        if ax is None:
            ax = plt.gca()
        xlim = ax.get_xlim()
        ylim = ax.get_ylim()

        # create grid to evaluate classifiermodel
        x = np.linspace(xlim[0], xlim[1], resolution)
        y = np.linspace(ylim[0], ylim[1], resolution)
        Y, X = np.meshgrid(y, x)
        xy = np.c_[X.ravel(), Y.ravel()]    #xy = np.array([X.ravel(), Y.ravel()]).T

        self._try_fit()
        
        if ((hasattr(self.cv_search, &#39;decision_function&#39;)) and (len(self._states_labels) &lt; 3)):
            P = self.cv_search.decision_function(xy)
        else:
            P = self.cv_search.predict(xy)

        self.decision_function = P.reshape(X.shape)

        if ((hasattr(self.cv_search, &#39;decision_function&#39;)) and (len(self._states_labels) &lt; 3)):
            levels = [-1, 0, 1]
            linestyles = [&#39;--&#39;, &#39;-&#39;, &#39;--&#39;]
        else:
            list, j = [], 0
            for i in range(len(self.state_entries)):
                num = i-j
                if (i % 2) == 0:
                    list.append(0.5 + num*0.5)
                else:
                    j += 1
                    list.append(0.5 - num*0.5)
               
            levels = list.sort()
            linestyles = [&#39;-&#39;] * len(self.state_entries)

        ax.contour(X, Y, self.decision_function, colors=&#39;k&#39;,
                   alpha=0.5, levels=levels,
                   linestyles=linestyles)

        # plot support vectors
        if hasattr(self.cv_search, &#39;support_vectors_&#39;):
            if plot_support:
                ax.scatter(self.cv_search.support_vectors_[:, 0],
                           self.cv_search.support_vectors_[:, 1],
                           s=300,
                           alpha=0.7, linewidth=1,
                           facecolors=&#39;None&#39;, edgecolors=&#34;k&#34;)

        ax.set_xlim(xlim)
        ax.set_ylim(ylim)
    
    def plot_classifier(self, X=None, y=None, sample_weight=None, class_plot=True, save_fig=False, title=None):
        &#34;&#34;&#34;Plotting fuction for SVM fits

        Args:
            X (list, optional): The X-data to use. If None the Initial states are used: self.X_train. Defaults to None.
            y (list, optional): The y-data to use. If None the Initial states are used: self.y_train. Defaults to None.
            sample_weight (list, optional): The calculated weights. Defaults to None.
            class_plot (bool, optional): If True the classifiers plotted. Defaults to True.
            save_fig (bool, optional): If True the figure is saved. Defaults to False.
            title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

        Returns:
            ax (object): The figure object
        &#34;&#34;&#34;
        fig, ax = plt.subplots(figsize=self.figsize)

        if X is None:
            X = np.array(self.X_train)
            
        if y is None:
            y = np.array(self.y_train)
        
        if isinstance(sample_weight, int) == False:
            sample_weight = self.weights
        
        for i in np.unique(y):   
            plt.scatter(X[:, 0][y==i], X[:, 1][y==i], s=50 * sample_weight[y==i], alpha=self.alpha, cmap=&#39;Spectral&#39;, label=f&#39;State {int(i)}&#39;)
        
        if class_plot == True:
            self.plot_classifier_decision_function()

        ax.set_xlabel(&#34;I (V)&#34;), ax.set_ylabel(&#34;Q (V)&#34;)
        
        if title == None:
            kernel = self.cv_search.best_estimator_[-1].kernel
            title = self._get_file_name_from_path(self._filePath)
        
        ax.set_title(f&#39;Classifiter training plot, kernel: {kernel}\n&#39; + title)
        
        plt.legend()
        plt.tight_layout()
        
        if save_fig == True:
            self.save_fig(self.cv_search, name=&#39;classifier_plot&#39;,  format=&#39;.svg&#39;, dpi=600)
        plt.show()
        
        return ax
 
    def plot_testing(self, X=None, save_fig=False, title=None):
        &#34;&#34;&#34;A function for plotting the testing of a dataset.

        Args:
            X (list, optional): The X-data to use. If None the Initial states are used: self.X_test. Defaults to None.
            save_fig (bool, optional): If True the figure is saved. Defaults to False.
            title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

        Returns:
            ax (object): The figure object
        &#34;&#34;&#34;
    
        if X is None:
            X = self.X_test
        
        predcition = np.array(self.cv_search.predict(X))
        unique, counts = np.unique(predcition, return_counts=True)

        fig, ax = plt.subplots(figsize=(10, 6))

        for i in np.unique(predcition):   
            plt.scatter(X[:, 0][predcition==i], X[:, 1][predcition==i], s=25, alpha=self.alpha, cmap=&#39;Spectral&#39;, label=f&#39;State {int(i)}, {counts/len(predcition):.3}:.%&#39;)
        
        
        self.plot_classifier_decision_function(plot_support=False)

        ax.set_xlabel(&#34;I&#34;), ax.set_ylabel(&#34;Q&#34;)
        
        if title == None:
            kernel = self.cv_search.best_estimator_[-1].kernel
            title = self._get_file_name_from_path(self._filePath)
        
        ax.set_title(f&#39;Classifiter testing plot, kernel: {kernel}\n&#39; + title )
        
        plt.legend()
        plt.tight_layout()

        if save_fig == True:
            self.save_fig(self.cv_search, name=&#39;testing_plot&#39;,  format=&#39;.svg&#39;, dpi=600)

        return ax
    
    def plot_ROC(self, X=None, y=None, save_fig=False, title=None):
        &#34;&#34;&#34;Make ROC plots of FPR / TP.

        Args:
            X (list, optional): The X-data to use. If None the Initial states are used: self.X_test. Defaults to None.
            y (list, optional): The y-data to use. If None the Initial states are used: self.y_test. Defaults to None.
            save_fig (bool, optional): If True the figure is saved. Defaults to False.
            title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

        Returns:
            ax (object): The figure object
        &#34;&#34;&#34;
        from sklearn.metrics import roc_curve, auc
        
        fig, ax = plt.subplots(figsize=self.figsize)
        
        if X is None:
            X = self.X_test
            
        if y is None:
            y = self.y_test
        
        # compute y prediction probabilities:
        y_predicted_proba = self.cv_search.predict_proba(X)
        
        n_classes = y_predicted_proba.shape[1]
        
        FPR_list, TPR_list, y_list, y_predicted_proba_list = [], [], [], []
        for i in range(n_classes):
            y_i = np.where((y == i), 1, 0)
            
            # Compute ROC curve and ROC area
            FPR, TPR, _ = roc_curve(y_i, y_predicted_proba[:, i])
            roc_auc = auc(FPR, TPR)

            FPR_list.append(FPR), TPR_list.append(TPR)
            y_list.append(y_i), y_predicted_proba_list.append(y_predicted_proba[:, i])
            
            # plot the ROC curve
            ax.plot(FPR, TPR, label=f&#39;ROC curve state {i} (area = %0.3f)&#39; % roc_auc)
            
            
            
        # First aggregate all false positive rates
        all_fpr = np.unique(np.concatenate(FPR_list))

        # Then interpolate all ROC curves at this points
        mean_tpr = np.zeros_like(all_fpr)
        for i in range(n_classes):
            mean_tpr += np.interp(all_fpr, FPR_list[i], TPR_list[i])

        # Finally average it and compute AUC
        mean_tpr /= n_classes

        FPR_macro = all_fpr
        TPR_macro = mean_tpr
        roc_auc_macro = auc(FPR_macro, TPR_macro)   
                    
        # plot the macro ROC curve
        ax.plot(FPR_macro, TPR_macro, label=f&#39;macro-average ROC curve (area = %0.3f)&#39; % roc_auc_macro, linestyle=&#34;--&#34;)
             
        # plot the micro ROC curve
        FPR_micro, TPR_micro, _ = roc_curve(np.array(y_list).flatten(), np.array(y_predicted_proba_list).flatten())
        #FPR_micro, TPR_micro = np.array(FPR_list).flatten(), np.array(TPR_list).flatten()
        roc_auc_micro = auc(FPR_micro, TPR_micro)  
        
        ax.plot(FPR_micro, TPR_micro, label=f&#39;micro-average ROC curve (area = %0.3f)&#39; % roc_auc_micro, linestyle=&#34;--&#34;)
          
            
            
        ax.plot([0, 1], [0, 1], linestyle=&#39;--&#39;)
        ax.set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05], xlabel=&#39;False Positive Rate&#39;, ylabel=&#39;True Positive Rate&#39;)
        ax.legend(loc=&#34;lower right&#34;)
        
        if title == None:
            kernel = self.cv_search.best_estimator_[-1].kernel
            title = self._get_file_name_from_path(self._filePath)
        
        ax.set_title(f&#39;ROC plot, kernel: {kernel}\n&#39; + title )
        
        
        plt.tight_layout()
        
        if save_fig == True:
            self.save_fig(self.cv_search, name=&#39;roc_plot&#39;,  format=&#39;.svg&#39;, dpi=600)

        return ax
    
    def plot_cv_iterations(self, score_value=&#34;mean_test_score&#34;, save_fig=False, title=None):
        &#34;&#34;&#34;The function the plots the performance of each iteration of cross validation.

        Args:
            score_value (list, optional): The score value to plot on the y axis. If None &#34;mean_test_score&#34; is used. Defaults to None.
            save_fig (bool, optional): If True the figure is saved. Defaults to False.
            title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

        Returns:
            ax (object): The figure object
        &#34;&#34;&#34;
        results = pd.DataFrame(self.cv_search.cv_results_)
        results[&#34;params_str&#34;] = results.params.apply(str)
        results.drop_duplicates(subset=(&#34;params_str&#34;, &#34;iter&#34;), inplace=True)
        
        mean_scores = results.pivot(index=&#34;iter&#34;, columns=&#34;params_str&#34;, values=score_value)
        ax = mean_scores.plot(legend=False, alpha=0.6, figsize=(10, 6))

        labels = [
            f&#34;iter={i}\nn_samples={self.cv_search.n_resources_[i]}\nn_candidates={self.cv_search.n_candidates_[i]}&#34;
            for i in range(self.cv_search.n_iterations_)
        ]

        ax.set_xticks(range(self.cv_search.n_iterations_))
        ax.set_xticklabels(labels, rotation=45, multialignment=&#34;left&#34;)
        ax.set_title(&#34;Scores of candidates over iterations&#34;)
        
        if title == None:
            kernel = self.cv_search.best_estimator_[-1].kernel
            title = self._get_file_name_from_path(self._filePath)
        
        ax.set_title(f&#39;Scores of candidates over iterations, kernel: {kernel} \n&#39; + title)
        
        ax.set_ylabel(score_value.replace(&#34;_&#34;,&#34; &#34;))
        ax.set_xlabel(&#34;iterations&#34;)
        plt.tight_layout()
        
        if save_fig == True:
            self.save_fig(self.cv_search, name=&#39;cv_iterations&#39;,  format=&#39;.svg&#39;, dpi=600)
        
        return ax
    
    def plot_oscillation(self, x=None, y=None, X=None, size=None, mode=&#39;probability&#39;, title=None, state=1):
        &#34;&#34;&#34;Function for oscillation plot. For more information to see example &#34;quick_run&#34;.

        Args:
            x (_type_, optional): If None: self.probability_values or self.expectation_values. Defaults to None.
            y (_type_, optional): If None: self.h5data_log[&#39;axis&#39;]. Defaults to None.
            X (list, optional): The X-data to use. If None the Initial states are used: self.X_test. Defaults to None.
            size (int, optional): The size of the data set used. Must be integer. Defaults to None.
            mode (str, optional): Can be [&#39;probability&#39;,&#39;expectation&#39;]. Defaults to &#39;probability&#39;.
            title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.
            state (int, optional): The state to be calculated. Defaults to 1.

        Returns:
            ax (object): The figure object
        &#34;&#34;&#34;
        if title == None:
            title = self._get_file_name_from_path(self._filePath)
            
        if size == None:
            size = self._int_states.shape[1]

        if hasattr(self, &#39;_osc_state&#39;) == False:
            self._osc_state = None
        
        if hasattr(self, &#39;expectation_values&#39;) == False or size != self.size or self._osc_state != state:
            self.cal_expectation_values(X, size, state=state)

        self._osc_state = state
       
        fig, ax = plt.subplots(figsize=self.figsize)

        if y is None:
            if mode == &#39;expectation&#39;:
                y = self.expectation_values
                ax.set_ylabel(&#39;Expetaction Value&#39;)
                
            if mode == &#39;probability&#39;:
                y = self.probability_values
                if self._osc_state == &#39;all&#39;:
                    ax.set_ylabel(f&#39;Probability&#39;)
                else:
                    ax.set_ylabel(f&#39;Probability of state {int(self._osc_state)}&#39;)
        
        for i, key in enumerate(y.keys()): 
            if x is None:
                x = self.h5data_log[&#39;axis&#39;]
            
            if mode == &#39;probability&#39; and self._osc_state == &#39;all&#39;:
                y = np.array(self.probability_values[key])
                for j in range(y.shape[1]):
                    self.do_fit_oscillation(x=x, y=y[:,j], label=key + f&#39;, state {j}&#39;, ax=ax, color=list(mcolors.TABLEAU_COLORS.values())[j])
            else:
                self.do_fit_oscillation(x=x, y=y[key], label=key, ax=ax, color=list(mcolors.TABLEAU_COLORS.values())[i])
        
        ax.set_xlabel(self.h5data_log[&#39;name&#39;])
        ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
        
        fit_type = r&#39;$A \times sin(\omega x + \varphi) + c$&#39;
        ax.set_title(title + &#39;\n Fit type: &#39; + fit_type)
        
        plt.tight_layout()
        
        return ax
     
    def plot_param_effect(self, plot_dir=None, title=None):
        &#34;&#34;&#34;A function for plotting the effects on a score of a parameter.

        Args:
            plot_dir (dir, optional): A dir containing the score and parameter values. If None self._plot_dir is used Defaults to None.
            title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

        Returns:
            ax (object): The figure object
        &#34;&#34;&#34;
        if plot_dir == None:
            try:
                plot_dir = self._plot_dir
            except:
                print(&#39;self._plot_dir is not defined. Define using self.set_plot_dir()&#39;)
        
        try:
            std = plot_dir[&#39;score_std&#39;]
        except:
            std = None
        
        fig, ax = plt.subplots(figsize=self.figsize)
        
        ax.errorbar(plot_dir[&#39;param_value&#39;], plot_dir[&#39;score_value&#39;], yerr=std)
      
    
        if title == None:
            title = self._get_file_name_from_path(self._filePath)
        
        ax.set_title(f&#39;Scores of candidates over parameter\n&#39; + title)
        
        ax.set_ylabel(plot_dir[&#39;score_name&#39;].replace(&#34;_&#34;,&#34; &#34;))
        ax.set_xlabel(plot_dir[&#39;param_name&#39;].replace(&#34;_&#34;,&#34; &#34;))
        plt.tight_layout()
        
        return ax</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="quantum_fitter.readout_tools.fitting.Fitting" href="fitting.html#quantum_fitter.readout_tools.fitting.Fitting">Fitting</a></li>
<li><a title="quantum_fitter.readout_tools.loading.DataImport" href="loading.html#quantum_fitter.readout_tools.loading.DataImport">DataImport</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="quantum_fitter.readout_tools.readout.Readout" href="readout.html#quantum_fitter.readout_tools.readout.Readout">Readout</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="quantum_fitter.readout_tools.plotting.Plotting.plot_ROC"><code class="name flex">
<span>def <span class="ident">plot_ROC</span></span>(<span>self, X=None, y=None, save_fig=False, title=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Make ROC plots of FPR / TP.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>The X-data to use. If None the Initial states are used: self.X_test. Defaults to None.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>The y-data to use. If None the Initial states are used: self.y_test. Defaults to None.</dd>
<dt><strong><code>save_fig</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True the figure is saved. Defaults to False.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>_type_</code>, optional</dt>
<dd>Title of the figure. If None the data file name is used. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ax (object): The figure object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_ROC(self, X=None, y=None, save_fig=False, title=None):
    &#34;&#34;&#34;Make ROC plots of FPR / TP.

    Args:
        X (list, optional): The X-data to use. If None the Initial states are used: self.X_test. Defaults to None.
        y (list, optional): The y-data to use. If None the Initial states are used: self.y_test. Defaults to None.
        save_fig (bool, optional): If True the figure is saved. Defaults to False.
        title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

    Returns:
        ax (object): The figure object
    &#34;&#34;&#34;
    from sklearn.metrics import roc_curve, auc
    
    fig, ax = plt.subplots(figsize=self.figsize)
    
    if X is None:
        X = self.X_test
        
    if y is None:
        y = self.y_test
    
    # compute y prediction probabilities:
    y_predicted_proba = self.cv_search.predict_proba(X)
    
    n_classes = y_predicted_proba.shape[1]
    
    FPR_list, TPR_list, y_list, y_predicted_proba_list = [], [], [], []
    for i in range(n_classes):
        y_i = np.where((y == i), 1, 0)
        
        # Compute ROC curve and ROC area
        FPR, TPR, _ = roc_curve(y_i, y_predicted_proba[:, i])
        roc_auc = auc(FPR, TPR)

        FPR_list.append(FPR), TPR_list.append(TPR)
        y_list.append(y_i), y_predicted_proba_list.append(y_predicted_proba[:, i])
        
        # plot the ROC curve
        ax.plot(FPR, TPR, label=f&#39;ROC curve state {i} (area = %0.3f)&#39; % roc_auc)
        
        
        
    # First aggregate all false positive rates
    all_fpr = np.unique(np.concatenate(FPR_list))

    # Then interpolate all ROC curves at this points
    mean_tpr = np.zeros_like(all_fpr)
    for i in range(n_classes):
        mean_tpr += np.interp(all_fpr, FPR_list[i], TPR_list[i])

    # Finally average it and compute AUC
    mean_tpr /= n_classes

    FPR_macro = all_fpr
    TPR_macro = mean_tpr
    roc_auc_macro = auc(FPR_macro, TPR_macro)   
                
    # plot the macro ROC curve
    ax.plot(FPR_macro, TPR_macro, label=f&#39;macro-average ROC curve (area = %0.3f)&#39; % roc_auc_macro, linestyle=&#34;--&#34;)
         
    # plot the micro ROC curve
    FPR_micro, TPR_micro, _ = roc_curve(np.array(y_list).flatten(), np.array(y_predicted_proba_list).flatten())
    #FPR_micro, TPR_micro = np.array(FPR_list).flatten(), np.array(TPR_list).flatten()
    roc_auc_micro = auc(FPR_micro, TPR_micro)  
    
    ax.plot(FPR_micro, TPR_micro, label=f&#39;micro-average ROC curve (area = %0.3f)&#39; % roc_auc_micro, linestyle=&#34;--&#34;)
      
        
        
    ax.plot([0, 1], [0, 1], linestyle=&#39;--&#39;)
    ax.set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05], xlabel=&#39;False Positive Rate&#39;, ylabel=&#39;True Positive Rate&#39;)
    ax.legend(loc=&#34;lower right&#34;)
    
    if title == None:
        kernel = self.cv_search.best_estimator_[-1].kernel
        title = self._get_file_name_from_path(self._filePath)
    
    ax.set_title(f&#39;ROC plot, kernel: {kernel}\n&#39; + title )
    
    
    plt.tight_layout()
    
    if save_fig == True:
        self.save_fig(self.cv_search, name=&#39;roc_plot&#39;,  format=&#39;.svg&#39;, dpi=600)

    return ax</code></pre>
</details>
</dd>
<dt id="quantum_fitter.readout_tools.plotting.Plotting.plot_classifier"><code class="name flex">
<span>def <span class="ident">plot_classifier</span></span>(<span>self, X=None, y=None, sample_weight=None, class_plot=True, save_fig=False, title=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plotting fuction for SVM fits</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>The X-data to use. If None the Initial states are used: self.X_train. Defaults to None.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>The y-data to use. If None the Initial states are used: self.y_train. Defaults to None.</dd>
<dt><strong><code>sample_weight</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>The calculated weights. Defaults to None.</dd>
<dt><strong><code>class_plot</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True the classifiers plotted. Defaults to True.</dd>
<dt><strong><code>save_fig</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True the figure is saved. Defaults to False.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>_type_</code>, optional</dt>
<dd>Title of the figure. If None the data file name is used. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ax (object): The figure object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_classifier(self, X=None, y=None, sample_weight=None, class_plot=True, save_fig=False, title=None):
    &#34;&#34;&#34;Plotting fuction for SVM fits

    Args:
        X (list, optional): The X-data to use. If None the Initial states are used: self.X_train. Defaults to None.
        y (list, optional): The y-data to use. If None the Initial states are used: self.y_train. Defaults to None.
        sample_weight (list, optional): The calculated weights. Defaults to None.
        class_plot (bool, optional): If True the classifiers plotted. Defaults to True.
        save_fig (bool, optional): If True the figure is saved. Defaults to False.
        title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

    Returns:
        ax (object): The figure object
    &#34;&#34;&#34;
    fig, ax = plt.subplots(figsize=self.figsize)

    if X is None:
        X = np.array(self.X_train)
        
    if y is None:
        y = np.array(self.y_train)
    
    if isinstance(sample_weight, int) == False:
        sample_weight = self.weights
    
    for i in np.unique(y):   
        plt.scatter(X[:, 0][y==i], X[:, 1][y==i], s=50 * sample_weight[y==i], alpha=self.alpha, cmap=&#39;Spectral&#39;, label=f&#39;State {int(i)}&#39;)
    
    if class_plot == True:
        self.plot_classifier_decision_function()

    ax.set_xlabel(&#34;I (V)&#34;), ax.set_ylabel(&#34;Q (V)&#34;)
    
    if title == None:
        kernel = self.cv_search.best_estimator_[-1].kernel
        title = self._get_file_name_from_path(self._filePath)
    
    ax.set_title(f&#39;Classifiter training plot, kernel: {kernel}\n&#39; + title)
    
    plt.legend()
    plt.tight_layout()
    
    if save_fig == True:
        self.save_fig(self.cv_search, name=&#39;classifier_plot&#39;,  format=&#39;.svg&#39;, dpi=600)
    plt.show()
    
    return ax</code></pre>
</details>
</dd>
<dt id="quantum_fitter.readout_tools.plotting.Plotting.plot_classifier_decision_function"><code class="name flex">
<span>def <span class="ident">plot_classifier_decision_function</span></span>(<span>self, resolution=350, ax=None, plot_support=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Plots the decision function for a 2D decision function</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>resolution</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Resolution of the plotted decision function. Defaults to 350.</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>string</code>, optional</dt>
<dd>The plot ax to use, if ax=None then new ax is generated. Defaults to None.</dd>
<dt><strong><code>plot_support</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Plots exstra data, just nicense. Defaults to True.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_classifier_decision_function(self, resolution=350, ax=None, plot_support=True):
    &#34;&#34;&#34;Plots the decision function for a 2D decision function

    Args:
        resolution (int, optional): Resolution of the plotted decision function. Defaults to 350.
        ax (string, optional): The plot ax to use, if ax=None then new ax is generated. Defaults to None.
        plot_support (bool, optional): Plots exstra data, just nicense. Defaults to True.
    &#34;&#34;&#34;
    if ax is None:
        ax = plt.gca()
    xlim = ax.get_xlim()
    ylim = ax.get_ylim()

    # create grid to evaluate classifiermodel
    x = np.linspace(xlim[0], xlim[1], resolution)
    y = np.linspace(ylim[0], ylim[1], resolution)
    Y, X = np.meshgrid(y, x)
    xy = np.c_[X.ravel(), Y.ravel()]    #xy = np.array([X.ravel(), Y.ravel()]).T

    self._try_fit()
    
    if ((hasattr(self.cv_search, &#39;decision_function&#39;)) and (len(self._states_labels) &lt; 3)):
        P = self.cv_search.decision_function(xy)
    else:
        P = self.cv_search.predict(xy)

    self.decision_function = P.reshape(X.shape)

    if ((hasattr(self.cv_search, &#39;decision_function&#39;)) and (len(self._states_labels) &lt; 3)):
        levels = [-1, 0, 1]
        linestyles = [&#39;--&#39;, &#39;-&#39;, &#39;--&#39;]
    else:
        list, j = [], 0
        for i in range(len(self.state_entries)):
            num = i-j
            if (i % 2) == 0:
                list.append(0.5 + num*0.5)
            else:
                j += 1
                list.append(0.5 - num*0.5)
           
        levels = list.sort()
        linestyles = [&#39;-&#39;] * len(self.state_entries)

    ax.contour(X, Y, self.decision_function, colors=&#39;k&#39;,
               alpha=0.5, levels=levels,
               linestyles=linestyles)

    # plot support vectors
    if hasattr(self.cv_search, &#39;support_vectors_&#39;):
        if plot_support:
            ax.scatter(self.cv_search.support_vectors_[:, 0],
                       self.cv_search.support_vectors_[:, 1],
                       s=300,
                       alpha=0.7, linewidth=1,
                       facecolors=&#39;None&#39;, edgecolors=&#34;k&#34;)

    ax.set_xlim(xlim)
    ax.set_ylim(ylim)</code></pre>
</details>
</dd>
<dt id="quantum_fitter.readout_tools.plotting.Plotting.plot_cv_iterations"><code class="name flex">
<span>def <span class="ident">plot_cv_iterations</span></span>(<span>self, score_value='mean_test_score', save_fig=False, title=None)</span>
</code></dt>
<dd>
<div class="desc"><p>The function the plots the performance of each iteration of cross validation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>score_value</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>The score value to plot on the y axis. If None "mean_test_score" is used. Defaults to None.</dd>
<dt><strong><code>save_fig</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True the figure is saved. Defaults to False.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>_type_</code>, optional</dt>
<dd>Title of the figure. If None the data file name is used. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ax (object): The figure object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_cv_iterations(self, score_value=&#34;mean_test_score&#34;, save_fig=False, title=None):
    &#34;&#34;&#34;The function the plots the performance of each iteration of cross validation.

    Args:
        score_value (list, optional): The score value to plot on the y axis. If None &#34;mean_test_score&#34; is used. Defaults to None.
        save_fig (bool, optional): If True the figure is saved. Defaults to False.
        title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

    Returns:
        ax (object): The figure object
    &#34;&#34;&#34;
    results = pd.DataFrame(self.cv_search.cv_results_)
    results[&#34;params_str&#34;] = results.params.apply(str)
    results.drop_duplicates(subset=(&#34;params_str&#34;, &#34;iter&#34;), inplace=True)
    
    mean_scores = results.pivot(index=&#34;iter&#34;, columns=&#34;params_str&#34;, values=score_value)
    ax = mean_scores.plot(legend=False, alpha=0.6, figsize=(10, 6))

    labels = [
        f&#34;iter={i}\nn_samples={self.cv_search.n_resources_[i]}\nn_candidates={self.cv_search.n_candidates_[i]}&#34;
        for i in range(self.cv_search.n_iterations_)
    ]

    ax.set_xticks(range(self.cv_search.n_iterations_))
    ax.set_xticklabels(labels, rotation=45, multialignment=&#34;left&#34;)
    ax.set_title(&#34;Scores of candidates over iterations&#34;)
    
    if title == None:
        kernel = self.cv_search.best_estimator_[-1].kernel
        title = self._get_file_name_from_path(self._filePath)
    
    ax.set_title(f&#39;Scores of candidates over iterations, kernel: {kernel} \n&#39; + title)
    
    ax.set_ylabel(score_value.replace(&#34;_&#34;,&#34; &#34;))
    ax.set_xlabel(&#34;iterations&#34;)
    plt.tight_layout()
    
    if save_fig == True:
        self.save_fig(self.cv_search, name=&#39;cv_iterations&#39;,  format=&#39;.svg&#39;, dpi=600)
    
    return ax</code></pre>
</details>
</dd>
<dt id="quantum_fitter.readout_tools.plotting.Plotting.plot_oscillation"><code class="name flex">
<span>def <span class="ident">plot_oscillation</span></span>(<span>self, x=None, y=None, X=None, size=None, mode='probability', title=None, state=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Function for oscillation plot. For more information to see example "quick_run".</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>_type_</code>, optional</dt>
<dd>If None: self.probability_values or self.expectation_values. Defaults to None.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>_type_</code>, optional</dt>
<dd>If None: self.h5data_log['axis']. Defaults to None.</dd>
<dt><strong><code>X</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>The X-data to use. If None the Initial states are used: self.X_test. Defaults to None.</dd>
<dt><strong><code>size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The size of the data set used. Must be integer. Defaults to None.</dd>
<dt><strong><code>mode</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Can be ['probability','expectation']. Defaults to 'probability'.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>_type_</code>, optional</dt>
<dd>Title of the figure. If None the data file name is used. Defaults to None.</dd>
<dt><strong><code>state</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The state to be calculated. Defaults to 1.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ax (object): The figure object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_oscillation(self, x=None, y=None, X=None, size=None, mode=&#39;probability&#39;, title=None, state=1):
    &#34;&#34;&#34;Function for oscillation plot. For more information to see example &#34;quick_run&#34;.

    Args:
        x (_type_, optional): If None: self.probability_values or self.expectation_values. Defaults to None.
        y (_type_, optional): If None: self.h5data_log[&#39;axis&#39;]. Defaults to None.
        X (list, optional): The X-data to use. If None the Initial states are used: self.X_test. Defaults to None.
        size (int, optional): The size of the data set used. Must be integer. Defaults to None.
        mode (str, optional): Can be [&#39;probability&#39;,&#39;expectation&#39;]. Defaults to &#39;probability&#39;.
        title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.
        state (int, optional): The state to be calculated. Defaults to 1.

    Returns:
        ax (object): The figure object
    &#34;&#34;&#34;
    if title == None:
        title = self._get_file_name_from_path(self._filePath)
        
    if size == None:
        size = self._int_states.shape[1]

    if hasattr(self, &#39;_osc_state&#39;) == False:
        self._osc_state = None
    
    if hasattr(self, &#39;expectation_values&#39;) == False or size != self.size or self._osc_state != state:
        self.cal_expectation_values(X, size, state=state)

    self._osc_state = state
   
    fig, ax = plt.subplots(figsize=self.figsize)

    if y is None:
        if mode == &#39;expectation&#39;:
            y = self.expectation_values
            ax.set_ylabel(&#39;Expetaction Value&#39;)
            
        if mode == &#39;probability&#39;:
            y = self.probability_values
            if self._osc_state == &#39;all&#39;:
                ax.set_ylabel(f&#39;Probability&#39;)
            else:
                ax.set_ylabel(f&#39;Probability of state {int(self._osc_state)}&#39;)
    
    for i, key in enumerate(y.keys()): 
        if x is None:
            x = self.h5data_log[&#39;axis&#39;]
        
        if mode == &#39;probability&#39; and self._osc_state == &#39;all&#39;:
            y = np.array(self.probability_values[key])
            for j in range(y.shape[1]):
                self.do_fit_oscillation(x=x, y=y[:,j], label=key + f&#39;, state {j}&#39;, ax=ax, color=list(mcolors.TABLEAU_COLORS.values())[j])
        else:
            self.do_fit_oscillation(x=x, y=y[key], label=key, ax=ax, color=list(mcolors.TABLEAU_COLORS.values())[i])
    
    ax.set_xlabel(self.h5data_log[&#39;name&#39;])
    ax.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
    
    fit_type = r&#39;$A \times sin(\omega x + \varphi) + c$&#39;
    ax.set_title(title + &#39;\n Fit type: &#39; + fit_type)
    
    plt.tight_layout()
    
    return ax</code></pre>
</details>
</dd>
<dt id="quantum_fitter.readout_tools.plotting.Plotting.plot_param_effect"><code class="name flex">
<span>def <span class="ident">plot_param_effect</span></span>(<span>self, plot_dir=None, title=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A function for plotting the effects on a score of a parameter.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>plot_dir</code></strong> :&ensp;<code>dir</code>, optional</dt>
<dd>A dir containing the score and parameter values. If None self._plot_dir is used Defaults to None.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>_type_</code>, optional</dt>
<dd>Title of the figure. If None the data file name is used. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ax (object): The figure object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_param_effect(self, plot_dir=None, title=None):
    &#34;&#34;&#34;A function for plotting the effects on a score of a parameter.

    Args:
        plot_dir (dir, optional): A dir containing the score and parameter values. If None self._plot_dir is used Defaults to None.
        title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

    Returns:
        ax (object): The figure object
    &#34;&#34;&#34;
    if plot_dir == None:
        try:
            plot_dir = self._plot_dir
        except:
            print(&#39;self._plot_dir is not defined. Define using self.set_plot_dir()&#39;)
    
    try:
        std = plot_dir[&#39;score_std&#39;]
    except:
        std = None
    
    fig, ax = plt.subplots(figsize=self.figsize)
    
    ax.errorbar(plot_dir[&#39;param_value&#39;], plot_dir[&#39;score_value&#39;], yerr=std)
  

    if title == None:
        title = self._get_file_name_from_path(self._filePath)
    
    ax.set_title(f&#39;Scores of candidates over parameter\n&#39; + title)
    
    ax.set_ylabel(plot_dir[&#39;score_name&#39;].replace(&#34;_&#34;,&#34; &#34;))
    ax.set_xlabel(plot_dir[&#39;param_name&#39;].replace(&#34;_&#34;,&#34; &#34;))
    plt.tight_layout()
    
    return ax</code></pre>
</details>
</dd>
<dt id="quantum_fitter.readout_tools.plotting.Plotting.plot_testing"><code class="name flex">
<span>def <span class="ident">plot_testing</span></span>(<span>self, X=None, save_fig=False, title=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A function for plotting the testing of a dataset.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>The X-data to use. If None the Initial states are used: self.X_test. Defaults to None.</dd>
<dt><strong><code>save_fig</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True the figure is saved. Defaults to False.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>_type_</code>, optional</dt>
<dd>Title of the figure. If None the data file name is used. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ax (object): The figure object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_testing(self, X=None, save_fig=False, title=None):
    &#34;&#34;&#34;A function for plotting the testing of a dataset.

    Args:
        X (list, optional): The X-data to use. If None the Initial states are used: self.X_test. Defaults to None.
        save_fig (bool, optional): If True the figure is saved. Defaults to False.
        title (_type_, optional): Title of the figure. If None the data file name is used. Defaults to None.

    Returns:
        ax (object): The figure object
    &#34;&#34;&#34;

    if X is None:
        X = self.X_test
    
    predcition = np.array(self.cv_search.predict(X))
    unique, counts = np.unique(predcition, return_counts=True)

    fig, ax = plt.subplots(figsize=(10, 6))

    for i in np.unique(predcition):   
        plt.scatter(X[:, 0][predcition==i], X[:, 1][predcition==i], s=25, alpha=self.alpha, cmap=&#39;Spectral&#39;, label=f&#39;State {int(i)}, {counts/len(predcition):.3}:.%&#39;)
    
    
    self.plot_classifier_decision_function(plot_support=False)

    ax.set_xlabel(&#34;I&#34;), ax.set_ylabel(&#34;Q&#34;)
    
    if title == None:
        kernel = self.cv_search.best_estimator_[-1].kernel
        title = self._get_file_name_from_path(self._filePath)
    
    ax.set_title(f&#39;Classifiter testing plot, kernel: {kernel}\n&#39; + title )
    
    plt.legend()
    plt.tight_layout()

    if save_fig == True:
        self.save_fig(self.cv_search, name=&#39;testing_plot&#39;,  format=&#39;.svg&#39;, dpi=600)

    return ax</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="quantum_fitter.readout_tools.fitting.Fitting" href="fitting.html#quantum_fitter.readout_tools.fitting.Fitting">Fitting</a></b></code>:
<ul class="hlist">
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.do_fit" href="fitting.html#quantum_fitter.readout_tools.fitting.Fitting.do_fit">do_fit</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.do_fit_oscillation" href="fitting.html#quantum_fitter.readout_tools.fitting.Fitting.do_fit_oscillation">do_fit_oscillation</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.export_classifier" href="loading.html#quantum_fitter.readout_tools.loading.DataImport.export_classifier">export_classifier</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.import_classifier" href="loading.html#quantum_fitter.readout_tools.loading.DataImport.import_classifier">import_classifier</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.oscillations" href="fitting.html#quantum_fitter.readout_tools.fitting.Fitting.oscillations">oscillations</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.oscillations_guess" href="fitting.html#quantum_fitter.readout_tools.fitting.Fitting.oscillations_guess">oscillations_guess</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.set_classifier" href="fitting.html#quantum_fitter.readout_tools.fitting.Fitting.set_classifier">set_classifier</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.set_cv_params" href="fitting.html#quantum_fitter.readout_tools.fitting.Fitting.set_cv_params">set_cv_params</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.set_cv_search" href="fitting.html#quantum_fitter.readout_tools.fitting.Fitting.set_cv_search">set_cv_search</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.set_data" href="loading.html#quantum_fitter.readout_tools.loading.DataImport.set_data">set_data</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.set_dataset_size" href="loading.html#quantum_fitter.readout_tools.loading.DataImport.set_dataset_size">set_dataset_size</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.set_pipeline" href="fitting.html#quantum_fitter.readout_tools.fitting.Fitting.set_pipeline">set_pipeline</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.set_plot_dir" href="fitting.html#quantum_fitter.readout_tools.fitting.Fitting.set_plot_dir">set_plot_dir</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.fitting.Fitting.set_states" href="loading.html#quantum_fitter.readout_tools.loading.DataImport.set_states">set_states</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="Readout Tools Home">
<img src="https://cdn-icons-png.flaticon.com/512/2432/2432797.png" alt=""> Readout Tools
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="quantum_fitter.readout_tools" href="index.html">quantum_fitter.readout_tools</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="quantum_fitter.readout_tools.plotting.Plotting" href="#quantum_fitter.readout_tools.plotting.Plotting">Plotting</a></code></h4>
<ul class="">
<li><code><a title="quantum_fitter.readout_tools.plotting.Plotting.plot_ROC" href="#quantum_fitter.readout_tools.plotting.Plotting.plot_ROC">plot_ROC</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.plotting.Plotting.plot_classifier" href="#quantum_fitter.readout_tools.plotting.Plotting.plot_classifier">plot_classifier</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.plotting.Plotting.plot_classifier_decision_function" href="#quantum_fitter.readout_tools.plotting.Plotting.plot_classifier_decision_function">plot_classifier_decision_function</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.plotting.Plotting.plot_cv_iterations" href="#quantum_fitter.readout_tools.plotting.Plotting.plot_cv_iterations">plot_cv_iterations</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.plotting.Plotting.plot_oscillation" href="#quantum_fitter.readout_tools.plotting.Plotting.plot_oscillation">plot_oscillation</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.plotting.Plotting.plot_param_effect" href="#quantum_fitter.readout_tools.plotting.Plotting.plot_param_effect">plot_param_effect</a></code></li>
<li><code><a title="quantum_fitter.readout_tools.plotting.Plotting.plot_testing" href="#quantum_fitter.readout_tools.plotting.Plotting.plot_testing">plot_testing</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>